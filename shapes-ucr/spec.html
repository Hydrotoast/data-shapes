<!DOCTYPE html>
<html>
  <head>
    <title>RDF Data Shapes Use Cases and Requirements</title>
    <meta charset='utf-8'>
    <script src='http://www.w3.org/Tools/respec/respec-w3c-common'
            async class='remove'></script>
    <script class='remove'>
      var respecConfig = {
          specStatus: "FPWD",
          shortName:  "shapes-ucr",
          editors: [
                {   name:       "Karen Coyle",
                    url:        "http://kcoyle.net/",
                    company:    "DCMI",
                    companyURL: "http://dublincore.org/" },
					{   name:       "Simon Steyskal",
                    url:        "http://steyskal.info/",
                    company:    "WU Vienna",
                    companyURL: "http://www.wu.ac.at/infobiz/" }
          ],
          wg:           "RDF Data Shapes Working Group",
          wgURI:        "https://www.w3.org/2014/data-shapes",
          wgPublicList: "public-rdf-shapes",
          wgPatentURI:  "http://www.w3.org/2004/01/pp-impl/73865/status",
		  localBiblio:  {
			"xyz": {
				title:    "Sample Custom Reference",
				href:     "http://example.org/",
				"authors": [
					"S. Steyskal",
					"S. Davis"
				],
				publisher: "xyz"
		    }
		  }
      };
    </script>
  </head>
  <body>
    <section id='abstract'>
      <p>To foster the development of the RDF Data Shapes specification, this document includes a set of user stories, use cases, and requirements 
	  that motivate a simple read-write Linked Data architecture, based on HTTP access to web resources that describe their state using RDF. 
	  The starting point for the development of these use cases is a collection of user stories that provide realistic examples describing how 
	  people may use structural constraints to validate RDF instance data. The use cases themselves are captured in a narrative style that 
	  describes a behavior, or set of behaviors based on, and using scenarios from, these user stories. Note, that this document avoids 
	  the use of any specific vocabulary that might be introduced by the <abbr title="RDF Data Shapes">SHAPES</abbr> specification.</p>
    </section>

    <section id='sotd'>

    </section>
    
    <section class='informative'>
      <h1>Scope and Motivation</h1>
      <p>
        Once upon a time, there was a working group that needed to write a 
        specification using nothing but [[HTML5]].
      </p>
      <p>
        It decided to use ReSpec, they went to Last Call inside of a quarter 
        and to Rec within six months. They spent most of the rest of their 
        chartered time having fun in exotic place.
      </p>
      <p>
        The End.
      </p>
    </section>
	
	<section class='informative'>
      <h1>Organization of this Document</h1>
      <p>
        Once upon a time, there was a working group that needed to write a 
        specification using nothing but [[HTML5]].
      </p>
<p>This document is organized as follows:</p>
	<ul>
		<li><b><a href="#userstories" title="User Stories">User Stories</a></b>
			capture statements about system requirements written from a user
			or application perspective. They are typically lightweight and
			informal and can run from one line to a paragraph or two
			(sometimes described as an 'epic') [[xyz]]. 
			This document redacts a number of user stories around the theme of read/writeable linked data.
			Analysis of each user story reveals a
			number of (functional) use cases and other non-functional
			requirements. See <em>Device API Access Control Use Cases and Requirements</em> [[xyz]] for a good example
			of user stories and their analysis.</li>
	</ul>
	<ul>
		<li><b><a href="#usecases" title="Use Cases">Use Cases</a></b> are
			used to capture and model functional requirements. Use cases
			describe the systemâ€™s behavior under various conditions [[xyz]],
			cataloging who does what with the system, for what purpose, but
			without concern for system design or implementation. Each use case is identified by a
			reference number to aid cross-reference from other documentation;
			use case indexing in this document is based on rdb2rdf
			use cases [[xyz]]. A variety of styles may be used to capture use cases,
			from a simple narrative to a structured description with actors,
			pre/post conditions, step-by-step behaviors (as in <em>POWDER:
			Use Cases and Requirements</em> [[xyz]]), and non-functional requirements
			raised by the use case.</li>
	</ul>
	<ul>
		<li><b><a href="#requirements" title="Requirements">Requirements</a></b>
			list functional and non-functional or quality requirements, and the use cases
			they may be derived from. This approach is exemplified in the <em>Use Cases and Requirements for the Data
			Catalog Vocabulary</em> [[xyz]].</li>
	</ul>
    </section>

    <section>
      <h1 id="userstories">User Stories</h1>
		<!-- User Story 1 -->
		<section>
			<h2><dfn>S1</dfn>: The model's broken!</h2>
				<p>
					Validate RDFS (maybe also OWL) models
					The basic issue here is to ensure that the right kind of information is given for each property (or class) in the model, for example, to require that each property has to have a domain, or that classes have to be explicitly stated to be under some decomposition.
					Input data: the RDF representation of an RDFS (or OWL) ontology
					Input ontology: the ontology that represents RDFS (or OWL) syntax 
				</p>
			<!--	<section>
					<h3> OWL constraints(Stardog ICV)</h3>
					Each property has to have a specified domain that is a class: </br>
					<pre id="example_s11" class="example highlight"> rdf:Property <= exists rdfs:domain rdfs:Class</pre>
					Each class has to be specified to be under the top-level decomposition: 
					<pre id="example_s12" class="example highlight"> rdfs:Class <= { rdfs:Class, [and the other built-in classes] } union fills rdfs:subClassOf { ex:Endurant, ex:Perdurant }</pre>
					<div class="note">
						<p> Because this story works with the built-in RDF, RDFS, and OWL vocabulary, the prohibition of using this vocabulary in OWL axioms would have to be lifted. </p>
					</div>
				</section>
				<section>
					<h3> SPIN </h3>
					Example: Each property has to have a domain  </br>
					<pre id="example_s13" class="example highlight"> 
					rdf:Property
						spin:constraint [
							sp:text "ASK { NOT EXISTS { ?this rdfs:domain ?anyDomain } }"
						]
					</pre>
				</section>-->
		</section>
		
		<!-- User Story 2 -->
		<section>
			<h2><dfn>S2</dfn>: What's the name of that person?</h2>
				<p>For a tool to build list of names for named entity resolution of people to work correctly, every person has to have one or more names specified, each of which is a string. Constraints can be used to verify that particular sets of data have such names for each person.</p>
				<!--<section>
					<h3> OWL constraints(Stardog ICV)</h3>
					<pre id="example_s21" class="example highlight"> Person <= exists name xsd:string & all name xsd:string</pre>
				</section>
				<section>
					<h3> SPIN </h3>
					<pre id="example_s22" class="example highlight"> 
					ex:Person
						spin:constraint [
							sp:text "ASK { FILTER NOT EXISTS { ?this ex:name ?anyName } }" 
						] ;
						spin:constraint [
							sp:text "ASK { ?this ex:name ?name . FILTER (datatype(?name) != xsd:string) }" 
						] 
					</pre>
				</section>
				<section>
					<h3> ShEx </h3>
					<pre id="example_s23" class="example highlight"> 
						my:PersonShape { ex:name xsd:string }
					</pre>
				</section>-->
				<div class="note">
					<p>This is probably the simplest user story, both in terms of setup and requirements.  It illustrates the basic idea of checking to see whether for some RDF graph all nodes that belong to some type have the right kind of information specified for them.  The same story can be repeated for other tools that need particular information specified for the tool to work correctly.;</p>
				</div>
		</section>
		
		<!-- User Story 3 -->
		<section>
			<h2><dfn>S3</dfn>: Communicating back to users, kindly</h2>
				<p>Rather than rejecting or having yes/no, and discouraging users and rejecting a lot of data, have a number of responses that inform users of ways they could improve their data, while still accepting all but the truly unusable data. This requires levels of "validation". </p>
				<!--	<section>
						<h3> SPIN</h3>-->
						<p>In TopBraid EVN (a web-based data entry tool), we have instance edit forms with an OK button. When OK is pressed, a server callback is made to verify all if constraints have been violated. If violations exist, they are presented to the user and depending on the severity and server settings, the user may continue without fixing the errors. SPIN can represent constraints in various severity levels (see also <a href="http://spinrdf.org/spin.html#spin-constraint-construct">http://spinrdf.org/spin.html#spin-constraint-construct</a>)
						<ul>
							<li> spin:Fatal: We can stop checking immediately, no way to continue. </li>
							<li> spin:Error: Something should really be fixed. </li>
							<li> spin:Warning: Just report it back to the user but don't block him. </li>
							<li> spin:Info: Just to print something out, e.g. for debugging. </li>
						</ul>
						</p>
						<!--<p> Here is an example in SPIN, using the CONSTRUCT notation to produce a constraint violation - additional properties could be attached to each report, including pointers at the triple that is causing the issue. Not shown here, SPIN even has the ability to point at an INSERT/DELETE update query to fix a violation. </p>
						<pre id="example_s31" class="example"> 
						kennedys:Person
						  spin:constraint
							[ a sp:Construct ;
							   sp:text """
							      CONSTRUCT {
								     _:violation a spin:ConstraintViolation ;
								     spin:violationRoot ?this ;
								     spin:violationPath kennedys:spouse ;
								     spin:violationValue ?spouse ;
								     spin:violationLevel spin:Warning ;
								     rdfs:label "Same-sex marriage not permitted (in this model)"
							      }
							      WHERE {
								     ?this kennedys:spouse ?spouse .
								     ?this kennedys:gender ?gender .
								     ?spouse kennedys:gender ?spouseGender .
								     FILTER (?gender = ?spouseGender) .
							      }"""
							 ] .
						</pre>
					</section>-->
		</section>
				
		<!-- User Story 4 -->
		<section>
			<h2><dfn>S4</dfn>: Issue repository</h2>
				<p>An LDP Container <http://PendingIssues> accepts an IssueShape with a status of "assigned" or "unassigned". The LDP Container is an interface to a service storing data in a conventional relational database. The shapes are "closed" in that the system rejects documents with any triples for which it has no storage. The shapes validation process (initiated by the receiving system or a sender checking) rejects any document with "extraneous" triples.</p>
				<p>Any node in the graph may serve multiple roles, e.g. the same node may include properties for a SubmittingUser and for an AssignedEmployee.</p>
				<p>Later the issue gets resolved and is available at <http://OldIssues> without acquiring new type arcs. The constraints for <http://PendingIssues> are different from those for Issues at <http://OldIssues> </p>				
		</section>
				
		<!-- User Story 5 -->
		<section>
			<h2><dfn>S5</dfn>: Closed-world recognition (EPIM ReportingHub)</h2>
				<p>EPIM Project - petroleum operators on the Norwegian continental shell need to produce environment reports of what chemicals were dumped into the sea and gases to the air. There is a need for access rules on what operators can see what data from what oil and gas fields, and for complex constraints to run during import of XML files. SPIN was used to represent and evaluate those constraints.</p>
				<p>This is an example of very complex constraints that require many features from SPARQL to represent model-specific scenarios, including the comparison of incoming values against a controlled fact base, transformations from literal values to URIs, string operations, date comparisons etc. User-defined SPIN functions were used to make those complex queries maintainable.</p>
				<p>Details: <a href="https://www.w3.org/2014/data-shapes/wiki/EPIM_ReportingHub">EPIM ReportingHub</a></p>
		</section>
				
		<!-- User Story 6 -->
		<section>
			<h2><dfn>S6</dfn>: Closed-world recognition for e.g. for partial ontology import</h2>
				<p>Importing all of an ontology is not always a good practice. When an ontology is imported it is often the case that many concepts and properties will be irrelevant to the needs at hand. In addition transitive imports can lead to increased "Ontology Glut". An increasingly popular practice is to not do any imports but to explicitly declare the use of non-imported resources with rdfs:definedIn to provide the provenance to the authoritative defining point of the resource. Alternatively some way to constrain imports to avoid ontology glut might be useful.</p>
				<p>SPIN currently uses owl:imports to include other graphs. If no owl:imports statement is present, then the engine will not execute constraints stored in the remote schema. It is perfectly fine to have local copies of classes and properties defined elsewhere, without requiring the full contract. This is a common scenario in controlled environments, not the full Web. </p>
		</section>
				
		<!-- User Story 7 -->
		<section>
			<h2><dfn>S7</dfn>: Contract time intervals</h2>
				<p>OMG time ontology adopted by FIBO. end date *exists* but may not be specified. Some contracts (bonds) have an end date. </p>
				<p>(was S9)</p>
		</section>
				
		<!-- User Story 8 -->
		<section>
			<h2><dfn>S8</dfn>: card >= 0</h2>
				<p>Mention a property in a card>= 0 restriction, just to indicate an expectation that it will (or might) be there without requiring that it be there</p>
				<p>(ericP: may I replace this with a story with requirements for different cardinalities, including fixed cardinalities > 1 (2 comes up a lot, e.g. two biological parents)? I propose:)</p>
				<p>Clinical data requires specific cardinality constraints, e.g.
					<ul>
						<li>zero or one (optional) birth date.</li>
						<li>zero or more lab tests.</li>
						<li>one active patient marker.</li>
						<li>one or more emergency contact.</li>
						<li>two biological parents.</li>
					</ul>
				</p>
				<p>(was S10)</p>
		</section>
				
		<!-- User Story 9 -->
		<section>
			<h2><dfn>S9</dfn>: Model-Driven UI constraints</h2>
				<p>Need to have constraints provide model-driven validation of permissible values in user interfaces. A number of solutions and applications have been deployed which use SPIN to check constraints on permissible values to user interfaces. This overcomes the software debt that comes from using javascript that can readily become out-of-sync with the underlying models.</p>
				<p>The major requirement here is a declarative model of: 
					<ul>
						<li>which properties are relevant for a given class/instance?</li>
						<li>what is the value type of those properties?</li>
						<li>what is the valid cardinality (min/maxCount)?</li>
						<li>what is the interval of valid literal values (min/maxValue)?</li>
						<li>any other metadata typically needed to build forms with input widgets.</li>
					</ul>
				</p>
				<p>A meta-requirement here is to be able to make use of the information above without having to run something like SPARQL queries, i.e. the model should be sufficiently high level so that all kinds of tools can use that information. However, at the same time there are many advanced constraints that need to be validated (either on server or client) before a form can be submitted. These constraints are not necessarily "structural" information, but rather executable code that returns error messages. </p>
				<p>(was S11)</p>
		</section>
				
		<!-- User Story 10 -->
		<section>
			<h2><dfn>S10</dfn>: App Interoperability</h2>
				<p>For example, cimba.co acts as a decentralized twitter, operating over LDP. For another app to interoperate, it needs to know what data shapes cimba reads and write. This is currently documented with diagrams and sparql templates. The SPARQL is fairly complex and hard to read, and it seems like another language might make it easier to write interoperable programs. </p>
				<p>(was S12)</p>
		</section>	

		<!-- User Story 11 -->
		<section>
			<h2><dfn>S11</dfn>: Specification and validation of metadata templates for immunological experiments</h2>
				<p>Systems Biology is playing an increasingly important role in unraveling the complexity of human immune responses. A key aspect of this approach involves the analysis and integration of data from a multiplicity of high-throughput immune profiling methods to understand (and eventually predict) the immunological response to infection and vaccination under diverse conditions. To this end, the Human Immunology Project Consortium (HIPC) was established by the National Institute of Allergy and Infectious Diseases (NIAID) of the US National Institutes of Health (NIH). This consortium generates a wide variety of phenotypic and molecular data from well-characterized patient cohorts, including genome-wide expression profiling, high-dimensional flow cytometry and serum cytokine concentrations. The adoption and adherence to data standards is critical to enable data integration across HIPC centers, and facilitate data re-use by the wider scientific community.</p>
				<p>In collaboration with ImmPort, we have developed a set of spreadsheet-based templates to capture the metadata associated with experimental results such as Flow Cytometry results and Multiplex Bead Array Assay (MBAA) results. These templates contain metadata elements that are either required or optional, but importantly, define the value of the field to specific datatypes (e.g. string, integer, decimal, date) that may be restricted by length or to a regular expression pattern, and limited to specific categorical values or terminology trees/class expressions of a target ontology, especially those drawn from existing ontologies such as Cell Ontology (CL) and Protein Ontology (PO). Once filled out, these spreadsheets are programmatically validated. The values are then stored in a database and are used to power web applications and application programming interfaces.</p>
				<p>Given the rapid change in the kinds of experiments performed and the evolving requirements concerning relevant metadata, it is crucial that a language to define these metadata constraints enable us to define different sets of metadata fields and values sets in a modular manner. In addition to HIPC, there are other immunology consortia that might involve different requirements as to how data templates should be defined according to specific needs. It should be relatively straightforward to substitute one set of shape expressions for another. It is also important that the shapes themselves are versioned and the results of validation record the version of the shape expression. It should be possible to validate data using any set of developed shapes.</p>
				<p>Ideally, the shapes language should be readable by computers in order to automatically generate template forms with restriction to specified values. Moreover, libraries and tools to construct and validate templates and their instance data should be readily available. </p>
				<p>(was S13)</p>
		</section>		
		
		<!-- User Story 12 -->
		<section>
			<h2><dfn>S12</dfn>: Validation of Dataset Descriptions</h2>
				<p>Access to consistent, high-quality metadata is critical to finding, understanding, exchanging, and reusing scientific data. The W3C Health Care and Life Sciences Interest Group (HCLSIG) has developed consensus among participating stakeholders on key metadata elements and their value sets for description of HCLS datasets. This <a href="http://tinyurl.com/hcls-dataset-description">specification</a>, written as a W3C note, meets key functional requirements, reuses existing vocabularies, is expressed using the Resource Description Framework (RDF). It provides guidance for minimal data description, versioning, provenance, statistics. We would like to use RDF Shapes to specify these constraints and validate the correctness of HCLS dataset descriptions.</p>
				<p>The specification defines a 3 component model for summary,versioning, and distribution-level descriptions. Each component has access to a specific set of metadata elements and these are specified as MUST, SHOULD, MAY, and MUST NOT. As such there are different conformance criteria for each level. Metadata values are either unrestrained rdfs:Literals, constrained rdfs:Literals, URIs with a specified URI pattern, or instances of a specified URI-identified type, or a disjunction of URI-specified types.</p>
				<p>Cardinalities and ranges are covered by all existing proposals, so I guess the interesting bit here is how to represent that certain constraints only apply in certain contexts ("levels: summary, version, distribution"). </p></p>				<p>(was S15)</p>
		</section>	
		
		<!-- User Story 13 -->
		<section>
			<h2><dfn>S13</dfn>: Constraints and controlled reasoning. We need both!</h2>
				<p>A use-case we were facing recently and have discussed in [1], was revolving around the integration of distributed configurations (i.e. object-oriented models) with RDFS and SPARQL. By using Semantic Web technologies for achieving this task we: 
					<ul>
						<li>aimed to provide a convenient way to perform certain tasks on the global view such as: </li>
							<ul>
								<li>querying it (and thus all underlying local schemas) </li>
								<li>perform constraint checks (i.e. checking integrity constraints) </li>
								<li>perform reasoning or consistency checks. </li>
							</ul>
						<li>wanted to leverage the use of SWT in configuration management. </li>
					</ul>
				</p>
				<p>(was S16)</p>
		</section>	

		<!-- User Story 14 -->
		<section>
			<h2><dfn>S14</dfn>: </h2>
				<p></p>
				<p>(was S1)</p>
		</section>	
		
		<!-- User Story 15 -->
		<section>
			<h2><dfn>S15</dfn>: </h2>
				<p></p>
				<p>(was S1)</p>
		</section>		
		
		<!-- User Story 16 -->
		<section>
			<h2><dfn>S16</dfn>: </h2>
				<p></p>
				<p>(was S1)</p>
		</section>	
		
		<!-- User Story 17 -->
		<section>
			<h2><dfn>S17</dfn>: </h2>
				<p></p>
				<p>(was S1)</p>
		</section>	

		<!-- User Story 18 -->
		<section>
			<h2><dfn>S18</dfn>: </h2>
				<p></p>
				<p>(was S1)</p>
		</section>	
	</section>
	
	<section>
		<h1 id="usecases">Use Cases</h1>
		<!-- User Case 1 -->
		<section>
			<h2><dfn>UC1</dfn>: </h2>
		</section>
	</section>
	<section>
		<h1 id="requirements">Requirements</h1>
			<p>This section lists the requirements arising from the use-cases catalogued in this document. Specific requirements that have been de-prioritized or rejected have been left in the document for completeness, but are shown as struck out.</p>
			<dl>
				<dt><dfn>R1</dfn>:</dt>
				<dd>The system shall provide the ability to create containers for composing resources, from <a>S1</a>.</dd>
				<dt><dfn>R2</dfn>:</dt>
				<dd>The system shall provide the ability to create containers for composing resources, from <a>S1</a>.</dd>
			</dl>
	</section>
	<!--
	<pre id="example1" class="example highlight">
					@prefix ro:  &lt;http://purl.org/wf4ever/ro#&gt; .
					@prefix dct: &lt;http://purl.org/dc/terms/&gt; .
					@prefix ore: &lt;http://www.openarchives.org/ore/&gt; .
					@prefix xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt; .

					&lt;&gt; a ro:ResearchObject, ore:Aggregation ;
						dct:created "2012-12-01"^^xsd:dateTime .
				</pre>
				<div class="note">
						<p>
							The basic facilities provided by <a href="#ch_domain"><code>rdfs:domain</code></a>
							and <a href="#ch_range"><code>rdfs:range</code></a> do not provide any
							direct way to indicate property restrictions that are local to a class.
							Although it is possible to combine use <a href="#ch_domain"><code>rdfs:domain</code></a>
							and <a href="#ch_range"><code>rdfs:range</code></a> with sub-property
							hierarchies, direct support for such declarations are provided by richer
							Web Ontology languages such as OWL.
					</p>
				</div>-->
    <section class='appendix'>
      <h2>Acknowledgements</h2>
      <p>
       We would like to acknowledge the contributions of user story authors: Dean Allemang, Anamitra Bhattacharyya, Karen Coyle, Nick Crossley, Michel Dumontier, Sandro Hawke, Dimitris Kontokostas, Holger Knublauch, David Martin, Dave McComb, Peter F. Patel-Schneider, Axel Polleres, Eric Prud'hommeaux, Arthur Ryman, Steve Speicher, and Simon Steyskal.
      </p>
    </section>
    
    <section id='tof'></section>
  </body>
</html>